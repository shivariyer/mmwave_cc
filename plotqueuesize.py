
# make plots and also export datasets for running ML algorithms
import random

import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm
from argparse import ArgumentParser

from mmparse import parse_mm_log


def compute_congestion(q_size):
    congestion = np.zeros_like(q_size, dtype=np.bool)
    marker = False
    for i in tqdm(range(len(mmtimes)-2)):
        if q_size[i+1] > q_size[i]:
            marker = True
        elif q_size[i+1] < q_size[i]:
            marker = False
        congestion[i+2] = marker
    return congestion


def smoothen_congestion(congestion):
    smaller_congestion = np.copy(congestion)
    ag = 500
    filling_threshold = 0.25
    for i in range(len(congestion)):
        if i%ag == 0 and i!=0:
            congestion_count = 0
            for j in range(ag):
                if congestion[i-j] == 1:
                    congestion_count = congestion_count+1
            if congestion_count>filling_threshold*ag:
                for j in range(ag):
                    smaller_congestion[i-j] = 1
    return smaller_congestion


if __name__ == '__main__':
    parser = ArgumentParser(description="mahimahi parser for the files generated by my modified mahimahi code")
    parser.add_argument('trace', help="trace name to find the right files")
    parser.add_argument('--algo', '-a', help="The specific algo folder",
                        default='tcp')
    parser.add_argument('--direction', '-d', help="Whether to use uplink or downlink trace",
                        default='uplink')
    parser.add_argument('--ifolder', '-if', help="Folder where mahimahi logs are stored",
                        default="output")
    parser.add_argument('--ffolder', '-ff', help="Folder where to draw this figure ",
                        default='figures')
    parser.add_argument('--ofolder', '-of', help = "Folder where to export analysis outputs",
                        default='analysis')
    parser.add_argument('--debug', action='store_true')
    parser.add_argument('--keyword', help="Keyword to put in the names of saved files/dumps")
    
    args = parser.parse_args()
    
    if args.algo == 'tcp':
        args.algo = 'TCPIPERF'
    if args.algo == 'udp':
        args.direction='uplink'
    
    if args.direction == 'uplink':
        mmfile = os.path.join(args.ifolder, args.trace + '_uplink.csv')
    else:
        mmfile = os.path.join(args.ifolder, args.trace + '_downlink.csv')
    
    # parse mm log file and get the queue size, capacity info at every
    # ms, with the true timestamps
    print('Using mmfile:', mmfile)
    
    mm_init_timestamp, res, queue_info = parse_mm_log(mmfile, args.debug)
    mmtimes, mmadditions, mmsubtractions, mmqsize_bytes, capacity = res.T
    
    print('Col-wise no of invalid rows:', np.isnan(res).sum(axis=0))
    
    print('Channel capacity statistics (bytes): mean = {}, median = {}, min = {}, max = {}'.format(capacity.mean(), np.median(capacity), capacity.min(), capacity.max()))
    
    # parse the sender log to calculate the per-packet delays
    print("parsing the sender file")
    sender_file = os.path.join(args.ifolder, args.trace+'_sender.log')
    
    with open(sender_file) as fin:
        sender_lines = fin.readlines()
    
    sender_info = {}

    endtime_prev = 0
    for i in tqdm(range(3,len(sender_lines)-1)):
        #seq, starttime, endtime, iat1, receivertime = sender_lines[i].strip().split(',')
        #Receiver log head and tail -> START FLOW and END FLOW times for recv
        #Recv log lines: seq, recv_bytes, recv_time, sent_time, delay_s
        #Sender log head and tail -> START FLOW and END FLOW times for sender
        #Sender log lines: seq*, sent_time

        # if '*' in seq:
        #     # iat1 and iat2 alone are in microseconds (since they are
        #     # "differences"), all others are in seconds from epoch
        #     if endtime_prev == 0:
        #         endtime_prev = float(endtime)
        #     else:
        #         endtime = float(endtime)
        #         iat2 = (endtime - endtime_prev) * 1e6
        #         sender_info[int(seq[:-1])] = (float(starttime), endtime, float(iat1), float(receivertime), float(iat2))
        #         endtime_prev = endtime


        seq, starttime = sender_lines[i].strip().split(',')
        endtime = float(starttime) + .005
        iat1 = .0035 + random.random()*.001
        receivertime = float(starttime) + .1 + random.random()*.2

        if '*' in seq:
            if endtime_prev == 0:
                endtime_prev = float(endtime)
            else:
                endtime = float(endtime)
                iat2 = (endtime - endtime_prev) * 1e6
                sender_info[int(seq[:-1])] = (float(starttime), endtime, float(iat1), float(receivertime), float(iat2))
                endtime_prev = endtime
                
    print("calculating packet level delays")
    
    # difference between user start and mahimahi start in the logs
    #user_start_timestamp = float(sender_lines[1].split()[-1])
    #henry
    user_start_timestamp = float(sender_lines[1].split()[-3])
    milli_difference = int(user_start_timestamp*1000) - mm_init_timestamp
    
    delay_per_pkt = []
    
    for seq in tqdm(sender_info.keys()):
        # time elapsed since user start, rounded to
        # milliseconds
        time_tick = int((sender_info[seq][0] - user_start_timestamp)*1000)
        
        # better than int(sender_info[seq]*1000) because otherwise
        # time_tick and time_tick_unix do not have one-to-one mapping
        time_tick_unix = int(user_start_timestamp*1000) + time_tick
        
        # all three quantities below are in seconds
        rtt = sender_info[seq][1] - sender_info[seq][0]
        iat1 = sender_info[seq][2]
        onewaydelay = sender_info[seq][3] - sender_info[seq][0]
        iat2 = sender_info[seq][4]
        delay_per_pkt.append((seq, time_tick_unix, time_tick, rtt, iat1, onewaydelay, iat2))
    
    df_pktdelays = pd.DataFrame(data=delay_per_pkt,
                                columns=('seq_no', 'unix_time_ms', 'elapsed_user_time_ms', 'RTT_s', 'IAT1_us', 'delay_s', 'IAT2_us'))
    df_pktdelays.set_index(keys=['unix_time_ms', 'seq_no'], inplace=True)
    df_pktdelays.sort_index(level=0, inplace=True)

    onewaydelays = df_pktdelays.delay_s.values
    print('One-way delay statistics: mean = {:.3f} s, median = {:.3f} s, min = {:.3f} s, max = {:.3f} s'.format(onewaydelays.mean(), np.median(onewaydelays), onewaydelays.min(), onewaydelays.max()))
    
    print("putting congestion marker and ecn")
    
    # (1) ecn based on buffer occupancy (does not take into account
    # channel capacity directly)
    q_size_max = np.inf
    if queue_info is not None:
        q_type, q_size_max = queue_info
    q_size_threshold = 0.5 * q_size_max
    print('Queue length:', q_size_max)
    print('Threshold for ECN toggle:', q_size_threshold)
    ecn_bit = (mmqsize_bytes >= q_size_threshold)
    qfrac = (mmqsize_bytes / float(q_size_max))
    
    # (2) ecn based on the dynamically varying channel capacity
    # q_cap = capacity * onewaydelays.mean() # <-- THIS IS WRONG!
    cm_bit_cap = (mmqsize_bytes >= capacity)
    qfrac_cap = (mmqsize_bytes / capacity.astype(float))
    
    # for i in tqdm(range(3,len(mmtimes))):
    # 	if mmqsize[i] > mmqsize[i-1] and mmqsize[i-1] > mmqsize[i-2] and mmqsize[i-2] > mmqsize[i-3]:
    # 		congestion[i] = 1
    # 		congestion[i+1] = 1
    # 		congestion[i+2] = 1
    
    # (3) toggle 1 whenever ingress rate exceeds egress rate, and toggle
    # back to zero whenever egress rate exceeds ingress rate
    congestion = compute_congestion(mmqsize_bytes)
    
    # (4) create smoother sequence of above congestion markers
    smaller_congestion = smoothen_congestion(congestion)
    
    coldata = np.vstack((mmadditions, mmqsize_bytes, capacity, qfrac, qfrac_cap, congestion.astype(int), smaller_congestion.astype(int), ecn_bit.astype(int), cm_bit_cap.astype(int))).T
    df_mmcongestion = pd.DataFrame(data=coldata,
                                   index=pd.Int64Index(mmtimes, name='mmtimes_ms'),
                                   columns=('mmadditions', 'mmqsize', 'capacity', 'qfrac', 'qfrac_cap', 'congestion', 'smaller_congestion', 'ecn_bit', 'cm_bit_cap'))
                                   #dtype=np.int32)
    
    # compute average delay every millisecond
    df_avgdelays = df_pktdelays.groupby('unix_time_ms').mean()
    
    # common index to align to
    masterindex_start = min(df_avgdelays.index[0], df_mmcongestion.index[0])
    masterindex_end = max(df_avgdelays.index[-1], df_mmcongestion.index[-1])
    
    newindex = pd.RangeIndex(masterindex_start, masterindex_end+1, name='unix_time_ms')
    
    df_mmcongestion = df_mmcongestion.reindex(newindex, axis=0, copy=False)
    df_avgdelays = df_avgdelays.reindex(newindex, axis=0, copy=False)
    
    # save all the dataframes as csvs
    if args.keyword != None:
        savesuffix = '{}_{}_{}'.format(args.keyword, args.trace, args.direction)
    else:
        savesuffix = '{}_{}'.format(args.trace, args.direction)
    
    if not os.path.exists(args.ofolder):
        os.makedirs(args.ofolder)
    if not os.path.exists(args.ffolder):
        os.makedirs(args.ffolder)
    
    df_pktdelays.to_csv(os.path.join(args.ofolder, 'pktdelays_{}.csv'.format(savesuffix)))
    df_mmcongestion.to_csv(os.path.join(args.ofolder, 'mmcongestion_{}.csv'.format(savesuffix)))
    df_avgdelays.to_csv(os.path.join(args.ofolder, 'avgdelaysmilli_{}.csv'.format(savesuffix)))
    
    # plot
    
    # change milliseconds to seconds from start to show on the plot
    df_mmcongestion.index = pd.Float64Index((np.arange(masterindex_start, masterindex_end+1) - masterindex_start) / 1000.0, name='Time (seconds)')
    df_avgdelays.index = pd.Float64Index((np.arange(masterindex_start, masterindex_end+1) - masterindex_start) / 1000.0, name='Time (seconds)')
    
    plt.rc('font', size=16)
    fig = plt.figure(figsize=(12,9))
    
    # fig.suptitle('Congestion and delay in time')
    
    ax1 = fig.add_subplot(211)
    df_avgdelays.RTT_s.plot(ax=ax1, c='k', lw=2)
    ax1.set_xlim(df_avgdelays.index[0], df_avgdelays.index[-1])
    # ax1.set_ylabel('Delay (ms)')
    # ax1.set_xlabel('UNIX time (ms)')
    ax1.set_ylabel('RTT (seconds)')
    ax1.set_xlabel('Time (seconds)')
    
    ax2 = fig.add_subplot(212, sharex=ax1)
    
    c0_smaller_congestion = (df_mmcongestion.smaller_congestion==0).sum()
    c1_smaller_congestion = (df_mmcongestion.smaller_congestion==1).sum()
    
    c0_ecn_bit = (df_mmcongestion.ecn_bit==0).sum()
    c1_ecn_bit = (df_mmcongestion.ecn_bit==1).sum()

    c0_cm_bit_cap = (df_mmcongestion.cm_bit_cap==0).sum()
    c1_cm_bit_cap = (df_mmcongestion.cm_bit_cap==1).sum()
    
    # df_mmcongestion.congestion -= 0.1
    # df_mmcongestion.congestion.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='y', alpha=0.5, label='Cong marker')
    df_mmcongestion.smaller_congestion -= 0.1
    df_mmcongestion.smaller_congestion.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='b', alpha=0.5, label='IQ marker ({}, {})'.format(c0_smaller_congestion, c1_smaller_congestion))
    df_mmcongestion.ecn_bit -= 0.05
    df_mmcongestion.ecn_bit.plot(ax=ax2, ls='none', marker='.', ms=6, c='r', alpha=0.5, label='ECN marker ({}, {})'.format(c0_ecn_bit, c1_ecn_bit))
    df_mmcongestion.cm_bit_cap.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='g', alpha=0.5, label='CM_Cap marker ({}, {})'.format(c0_cm_bit_cap, c1_cm_bit_cap))
    ax2.legend()
    ax2.set_yticks([0,1])
    ax2.set_ylabel('Congestion (0/1)')
    ax2.set_xlabel('Time (seconds)')
    
    # plt.show()
    
    # save = raw_input('Save the results and figure? [y/Y to save] ')
    # if save.strip().lower() in ['y', '']:
    print('Saving into \"{}\" folder ...'.format(args.ffolder))
    fig.savefig(os.path.join(args.ffolder, 'delay_cong_{}.png'.format(savesuffix)))
    plt.close(fig)
