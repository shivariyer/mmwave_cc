
# make plots and also export datasets for running ML algorithms
import random

import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm
from argparse import ArgumentParser

from mmparse import parse_mm_log
import extract_from_raw_data as extract_data


def compute_congestion(q_size):
    congestion = np.zeros_like(q_size, dtype=np.bool)
    marker = False
    for i in tqdm(range(len(mmtimes)-2)):
        if q_size[i+1] > q_size[i]:
            marker = True
        elif q_size[i+1] < q_size[i]:
            marker = False
        congestion[i+2] = marker
    return congestion


def smoothen_congestion(congestion):
    smaller_congestion = np.copy(congestion)
    ag = 500
    filling_threshold = 0.25
    for i in range(len(congestion)):
        if i % ag == 0 and i != 0:
            congestion_count = 0
            for j in range(ag):
                if congestion[i-j] == 1:
                    congestion_count = congestion_count+1
            if congestion_count > filling_threshold*ag:
                for j in range(ag):
                    smaller_congestion[i-j] = 1
    return smaller_congestion


if __name__ == '__main__':
    parser = ArgumentParser(
        description="mahimahi parser for the files generated by my modified mahimahi code")
    parser.add_argument('trace', help="trace name to find the right files")
    parser.add_argument('--algo', '-a', help="The specific algo folder",
                        default='tcp')
    parser.add_argument('--direction', '-d', help="Whether to use uplink or downlink trace",
                        default='uplink')
    parser.add_argument('--ifolder', '-if', help="Folder where mahimahi logs are stored",
                        default="output")
    parser.add_argument('--ffolder', '-ff', help="Folder where to draw this figure ",
                        default='figures')
    parser.add_argument('--ofolder', '-of', help="Folder where to export analysis outputs",
                        default='analysis')
    parser.add_argument('--debug', action='store_true')
    parser.add_argument(
        '--keyword', help="Keyword to put in the names of saved files/dumps")

    args = parser.parse_args()

    if args.algo == 'tcp':
        args.algo = 'TCPIPERF'
    if args.algo == 'udp':
        args.direction = 'uplink'

    if args.direction == 'uplink':
        mmfile = os.path.join(args.ifolder, args.trace + '_uplink.csv')
    else:
        mmfile = os.path.join(args.ifolder, args.trace + '_downlink.csv')

    # create a clear file from the raw data which pairs
    # together all RTTs and inter_sent_times for every packet
    # this produces the tracename_packet_info.log file
    extract_data.extract()

    # parse mm log file and get the queue size, capacity info at every
    # ms, with the true timestamps
    print('Using mmfile:', mmfile)

    mm_init_timestamp, res, queue_info = parse_mm_log(mmfile, args.debug)
    mmtimes, mmadditions, mmsubtractions, mmqsize_bytes, capacity = res.T

    print('Col-wise no of invalid rows:', np.isnan(res).sum(axis=0))

    print('Channel capacity statistics (bytes): mean = {}, median = {}, min = {}, max = {}'.format(
        capacity.mean(), np.median(capacity), capacity.min(), capacity.max()))

    # parse the sender log to calculate the per-packet delays
    #print("parsing the sender file")
    #packet_info_file = os.path.join(args.ifolder, args.trace+'_sender.log')
    print("parsing the extracted file")
    packet_info_file = os.path.join(args.ifolder, 'tracename_packet_info.log')

    with open(packet_info_file) as fin:
        packet_lines = fin.readlines()

    packet_info = {}

    endtime_prev = 0
    for i in tqdm(range(1, len(packet_lines)-1)):
        my_frame, ts_frame, epoch_time, capture_time, payload_size, rtt, inter_sent_time = packet_lines[i].strip().split()
        packet_info[int(my_frame)] = (float(epoch_time), float(capture_time), float(rtt), float(inter_sent_time))

    print("calculating packet level delays")

    delay_per_pkt = []

    for my_frame in tqdm(packet_info.keys()):
        # time elapsed since user start, rounded to
        # milliseconds
        if my_frame == 1:
            user_start_timestamp = packet_info[my_frame][0]

        time_tick_rel = int(packet_info[my_frame][1]*1000)

        # better than int(packet_info[my_frame]*1000) because otherwise
        # time_tick and time_tick_unix do not have one-to-one mapping
        #time_tick_unix = int(user_start_timestamp*1000) + time_tick
        time_tick_unix = int(user_start_timestamp * 1000) + time_tick_rel

        # all three quantities below are in seconds
        rtt = packet_info[my_frame][2]
        iat1 = packet_info[my_frame][3]
        #onewaydelay = packet_info[my_frame][3] - packet_info[my_frame][0]
        #iat2 = packet_info[my_frame][4]
        delay_per_pkt.append((my_frame, time_tick_unix, rtt, iat1))

    df_pktdelays = pd.DataFrame(data=delay_per_pkt,
                                columns=('my_frame_no', 'unix_time_ms', 'RTT_s', 'IAT1_us'))
    df_pktdelays.set_index(
        keys=['unix_time_ms', 'my_frame_no'], inplace=True)
    df_pktdelays.sort_index(level=0, inplace=True)

    rtts = df_pktdelays.RTT_s.values
    print('RTT statistics: mean = {:.3f} s, median = {:.3f} s, min = {:.3f} s, max = {:.3f} s'.format(
        rtts.mean(), np.median(rtts), rtts.min(), rtts.max()))

    print("putting congestion marker and ecn")

    # (1) ecn based on buffer occupancy (does not take into account
    # channel capacity directly)
    q_size_max = np.inf
    if queue_info is not None:
        q_type, q_size_max = queue_info
    q_size_threshold = 0.5 * q_size_max
    print('Queue length:', q_size_max)
    print('Threshold for ECN toggle:', q_size_threshold)
    ecn_bit = (mmqsize_bytes >= q_size_threshold)
    qfrac = (mmqsize_bytes / float(q_size_max))

    # (2) ecn based on the dynamically varying channel capacity
    # q_cap = capacity * onewaydelays.mean() # <-- THIS IS WRONG!
    cm_bit_cap = (mmqsize_bytes >= capacity)
    qfrac_cap = (mmqsize_bytes / capacity.astype(float))

    # for i in tqdm(range(3,len(mmtimes))):
    # 	if mmqsize[i] > mmqsize[i-1] and mmqsize[i-1] > mmqsize[i-2] and mmqsize[i-2] > mmqsize[i-3]:
    # 		congestion[i] = 1
    # 		congestion[i+1] = 1
    # 		congestion[i+2] = 1

    # (3) toggle 1 whenever ingress rate exceeds egress rate, and toggle
    # back to zero whenever egress rate exceeds ingress rate
    congestion = compute_congestion(mmqsize_bytes)

    # (4) create smoother sequence of above congestion markers
    smaller_congestion = smoothen_congestion(congestion)

    coldata = np.vstack((mmadditions, mmqsize_bytes, capacity, qfrac, qfrac_cap, congestion.astype(
        int), smaller_congestion.astype(int), ecn_bit.astype(int), cm_bit_cap.astype(int))).T
    df_mmcongestion = pd.DataFrame(data=coldata,
                                   index=pd.Int64Index(
                                       mmtimes, name='mmtimes_ms'),
                                   columns=('mmadditions', 'mmqsize', 'capacity', 'qfrac', 'qfrac_cap', 'congestion', 'smaller_congestion', 'ecn_bit', 'cm_bit_cap'))
    # dtype=np.int32)

    # compute average delay every millisecond
    df_avgdelays = df_pktdelays.groupby('unix_time_ms').mean()

    # common index to align to
    masterindex_start = min(df_avgdelays.index[0], df_mmcongestion.index[0])
    # henry: changed end to a min function b/c the max was an epoch time
    # tshark is currently set to use relative time but this can be changed
    masterindex_end = min(df_avgdelays.index[-1], df_mmcongestion.index[-1])

    newindex = pd.RangeIndex(
        masterindex_start, masterindex_end+1, name='unix_time_ms')

    df_mmcongestion = df_mmcongestion.reindex(newindex, axis=0, copy=False)
    df_avgdelays = df_avgdelays.reindex(newindex, axis=0, copy=False)

    # save all the dataframes as csvs
    if args.keyword != None:
        savesuffix = '{}_{}_{}'.format(
            args.keyword, args.trace, args.direction)
    else:
        savesuffix = '{}_{}'.format(args.trace, args.direction)

    if not os.path.exists(args.ofolder):
        os.makedirs(args.ofolder)
    if not os.path.exists(args.ffolder):
        os.makedirs(args.ffolder)

    df_pktdelays.to_csv(os.path.join(
        args.ofolder, 'pktdelays_{}.csv'.format(savesuffix)))
    df_mmcongestion.to_csv(os.path.join(
        args.ofolder, 'mmcongestion_{}.csv'.format(savesuffix)))
    df_avgdelays.to_csv(os.path.join(
        args.ofolder, 'avgdelaysmilli_{}.csv'.format(savesuffix)))

    # plot

    # change milliseconds to seconds from start to show on the plot
    df_mmcongestion.index = pd.Float64Index((np.arange(
        masterindex_start, masterindex_end+1) - masterindex_start) / 1000.0, name='Time (seconds)')
    df_avgdelays.index = pd.Float64Index((np.arange(
        masterindex_start, masterindex_end+1) - masterindex_start) / 1000.0, name='Time (seconds)')

    plt.rc('font', size=16)
    fig = plt.figure(figsize=(12, 9))

    # fig.suptitle('Congestion and delay in time')

    ax1 = fig.add_subplot(211)
    df_avgdelays.RTT_s.plot(ax=ax1, c='k', lw=2)
    ax1.set_xlim(df_avgdelays.index[0], df_avgdelays.index[-1])
    # ax1.set_ylabel('Delay (ms)')
    # ax1.set_xlabel('UNIX time (ms)')
    ax1.set_ylabel('RTT (seconds)')
    ax1.set_xlabel('Time (seconds)')

    ax2 = fig.add_subplot(212, sharex=ax1)

    c0_smaller_congestion = (df_mmcongestion.smaller_congestion == 0).sum()
    c1_smaller_congestion = (df_mmcongestion.smaller_congestion == 1).sum()

    c0_ecn_bit = (df_mmcongestion.ecn_bit == 0).sum()
    c1_ecn_bit = (df_mmcongestion.ecn_bit == 1).sum()

    c0_cm_bit_cap = (df_mmcongestion.cm_bit_cap == 0).sum()
    c1_cm_bit_cap = (df_mmcongestion.cm_bit_cap == 1).sum()

    # df_mmcongestion.congestion -= 0.1
    # df_mmcongestion.congestion.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='y', alpha=0.5, label='Cong marker')
    df_mmcongestion.smaller_congestion -= 0.1
    df_mmcongestion.smaller_congestion.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='b',
                                            alpha=0.5, label='IQ marker ({}, {})'.format(c0_smaller_congestion, c1_smaller_congestion))
    df_mmcongestion.ecn_bit -= 0.05
    df_mmcongestion.ecn_bit.plot(ax=ax2, ls='none', marker='.', ms=6, c='r',
                                 alpha=0.5, label='ECN marker ({}, {})'.format(c0_ecn_bit, c1_ecn_bit))
    df_mmcongestion.cm_bit_cap.plot(ax=ax2, ls='none', marker='o', mew=0, ms=6, c='g',
                                    alpha=0.5, label='CM_Cap marker ({}, {})'.format(c0_cm_bit_cap, c1_cm_bit_cap))
    ax2.legend()
    ax2.set_yticks([0, 1])
    ax2.set_ylabel('Congestion (0/1)')
    ax2.set_xlabel('Time (seconds)')

    # plt.show()

    # save = raw_input('Save the results and figure? [y/Y to save] ')
    # if save.strip().lower() in ['y', '']:
    print('Saving into \"{}\" folder ...'.format(args.ffolder))
    fig.savefig(os.path.join(
        args.ffolder, 'delay_cong_{}.png'.format(savesuffix)))
    plt.close(fig)
